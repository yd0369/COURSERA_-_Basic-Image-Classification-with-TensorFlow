{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rhyme](https://rhyme.com/assets/img/logo-dark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Introduction\n",
    "\n",
    "Welcome to Basic Image Classification with TensorFlow.\n",
    "\n",
    "This graph describes the problem that we are trying to solve visually. We want to create and train a model that takes an image of a hand written digit as input and predicts the class of that digit, that is, it predicts the digit or it predicts the class of the input image.\n",
    "\n",
    "![Hand Written Digits Classification](images/1_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 16:45:27.354346: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-25 16:45:28.206611: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-25 16:45:30.260101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-25 16:45:30.260277: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-25 16:45:30.260294: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)\n",
    "print('Using TensorFlow version', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: The Dataset\n",
    "### Import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train size : 60000\n",
      "y_train size : 60000\n",
      "x_test  size : 10000\n",
      "y_test  size : 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train size :\", len(x_train))\n",
    "print(\"y_train size :\", len(y_train))\n",
    "print(\"x_test  size :\", len(x_test))\n",
    "print(\"y_test  size :\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes of Imported Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape : (60000, 28, 28)\n",
      "y_train shape : (60000,)\n",
      "x_test  shape : (10000, 28, 28)\n",
      "y_test  shape : (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape :', x_train.shape)\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('x_test  shape :', x_test.shape)\n",
    "print('y_test  shape :', y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot an Image Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Label :  3\n"
     ]
    }
   ],
   "source": [
    "test_image=12\n",
    "\n",
    "# Showing Input\n",
    "plt.imshow(x_train[test_image], cmap=\"binary\")\n",
    "plt.show()\n",
    "\n",
    "# Showing Output (Class)\n",
    "print(\"Class Label : \", y_train[test_image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train classes : {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "y_test  classes : {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train classes :\",set(y_train))\n",
    "print(\"y_test  classes :\",set(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: One Hot Encoding\n",
    "After this encoding, every label will be converted to a list with 10 elements and the element at index to the corresponding class will be set to 1, rest will be set to 0:\n",
    "\n",
    "| original label | one-hot encoded label |\n",
    "|------|------|\n",
    "| 5 | [0, 0, 0, 0, 0, 1, 0, 0, 0, 0] |\n",
    "| 7 | [0, 0, 0, 0, 0, 0, 0, 1, 0, 0] |\n",
    "| 1 | [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] |\n",
    "\n",
    "### Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded  = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validated Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape : (60000,)\n",
      "y_test  shape : (10000,)\n",
      "y_train_encoded shape : (60000, 10)\n",
      "y_test_encoded  shape : (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Without Encoded Shape\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('y_test  shape :', y_test.shape)\n",
    "\n",
    "# Encoded Shape\n",
    "print('y_train_encoded shape :', y_train_encoded.shape)\n",
    "print('y_test_encoded  shape :', y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Encoded Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train : [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] ---> 3\n",
      "y_test  : [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] ---> 9\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train :\", y_train_encoded[12], \"--->\", y_train[12])\n",
    "print(\"y_test  :\", y_test_encoded[12], \"--->\", y_test[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Neural Networks\n",
    "\n",
    "### Linear Equations\n",
    "\n",
    "![Single Neuron](images/1_2.png)\n",
    "\n",
    "The above graph simply represents the equation:\n",
    "\n",
    "\\begin{equation}\n",
    "y = w1 * x1 + w2 * x2 + w3 * x3 + b\n",
    "\\end{equation}\n",
    "\n",
    "Where the `w1, w2, w3` are called the weights and `b` is an intercept term called bias. The equation can also be *vectorised* like this:\n",
    "\n",
    "\\begin{equation}\n",
    "y = W . X + b\n",
    "\\end{equation}\n",
    "\n",
    "Where `X = [x1, x2, x3]` and `W = [w1, w2, w3].T`. The .T means *transpose*. This is because we want the dot product to give us the result we want i.e. `w1 * x1 + w2 * x2 + w3 * x3`. This gives us the vectorised version of our linear equation.\n",
    "\n",
    "A simple, linear approach to solving hand-written image classification problem - could it work?\n",
    "\n",
    "![Single Neuron with 784 features](images/1_3.png)\n",
    "\n",
    "### Neural Networks\n",
    "\n",
    "![Neural Network with 2 hidden layers](images/1_4.png)\n",
    "\n",
    "This model is much more likely to solve the problem as it can learn more complex function mapping for the inputs and outputs in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Preprocessing the Examples\n",
    "\n",
    "### Unrolling N-dimensional Arrays to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_reshaped = np.reshape(x_train, (60000, 784))\n",
    "x_test_reshaped  = np.reshape(x_test, (10000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :  (60000, 28, 28)\n",
      "x_test  shape :  (10000, 28, 28)\n",
      "x_train_reshaped shape :  (60000, 784)\n",
      "x_test_reshaped  shape :  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape : \", x_train.shape)\n",
    "print(\"x_test  shape : \", x_test.shape)\n",
    "print(\"x_train_reshaped shape : \", x_train_reshaped.shape)\n",
    "print(\"x_test_reshaped  shape : \", x_test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Pixel Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 22, 23, 24, 25, 30, 33, 35, 45, 48, 49, 50, 52, 53, 54, 55, 58, 61, 63, 66, 67, 73, 74, 75, 86, 88, 90, 91, 99, 101, 103, 116, 118, 122, 125, 126, 127, 131, 137, 138, 140, 141, 142, 150, 152, 153, 154, 155, 158, 166, 168, 181, 182, 188, 189, 190, 191, 192, 194, 200, 202, 205, 209, 210, 220, 224, 234, 235, 241, 242, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255}\n"
     ]
    }
   ],
   "source": [
    "print(set(x_train_reshaped[12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = np.mean(x_train_reshaped)\n",
    "x_std  = np.mean(x_train_reshaped)\n",
    "\n",
    "epsilon = 1e-10\n",
    "# if the values of x_std is too low will not effect data to be normalized so we add epsilon to help for better normalization\n",
    "\n",
    "# For Training dataset :\n",
    "x_train_norm = (x_train_reshaped - x_mean) / (x_std + epsilon)\n",
    "\n",
    "# For Testing dataset :\n",
    "x_test_norm = (x_test_reshaped - x_mean) / (x_std + epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Normalized Pixel Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-0.9999999999969986, -0.6398388795779748, 1.731221829847265, 3.2619065916281156, 1.9713292434599472, 3.652081138748725, 6.3833029685929885, 4.4624436596915285, 2.9317588979106772, 3.1418528848217746, 6.6234103822056705, 6.5633835288025, 5.302819607335917, 6.05315527487555, 5.062712193723234, 6.413316395294574, 3.5920542853455544, 4.822604780110552, 6.443329821996159, 0.050469934558487375, 6.653423808907256, 6.2632492617866475, 2.7516783377011653, 3.982228832466163, 0.5006713350822671, -0.7298791596827308, 2.5415843507900684, 3.562040858643969, 5.60295387435177, 5.002685340320064, 6.023141848173965, 6.233235835085062, -0.3397046125621217, 0.8908458822028762, -0.5497985994732189, 1.7012084031456796, -0.3096911858605364, 0.3506042015743405, 0.4406444816790965, 3.742121418853481, 4.762577926707381, 2.0913829502662886, 3.111839458120189, 2.4815574973868975, 4.732564500005796, 0.7407787486949496, 5.152752473827991, 6.593396955504086, -0.00955691884468325, 1.2510070026219, 3.5020140052407984, 0.8308190287997055, 0.5606981884854377, -0.09959719894943919, -0.8799462931906573, -0.6098254528763896, 0.6207250418886083, -0.7598925863843161, -0.939973146593828, 0.590711615187023, -0.2796777591589511, -0.8499328664890721, 2.6616380575964094, -0.8199194397874867, 4.70255107330421, 1.641181549742509, 1.2209935759203145, 2.0313560968631177, 1.0108995890092174, 5.723007581158112, 6.533370102100915, 1.1909801492187293, 0.4706579083806818, 0.9808861623076321, 2.811705191104336, 3.2318931649265306, 4.672537646602626, 4.042255685869334, 5.272806180634332, 6.5033566753993295, 1.5811546963393384, 3.6220677120471394, 0.6507384685901937, -0.24966433245736577, -0.7899060130859014, 3.201879738224945, 4.432430232989943, 4.64252421990104, 6.473343248697744, 2.781691764402751, -0.9099597198922427}\n"
     ]
    }
   ],
   "source": [
    "print(set(x_train_norm[12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Creating a Model\n",
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation=\"relu\", input_shape=(784,)),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "\n",
    "The first step in the node is the linear sum of the inputs:\n",
    "\\begin{equation}\n",
    "Z = W . X + b\n",
    "\\end{equation}\n",
    "\n",
    "The second step in the node is the activation function output:\n",
    "\n",
    "\\begin{equation}\n",
    "A = f(Z)\n",
    "\\end{equation}\n",
    "\n",
    "Graphical representation of a node where the two operations are performed:\n",
    "\n",
    "![ReLU](images/1_5.png)\n",
    "\n",
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7: Training the Model\n",
    "\n",
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 18:35:56.569157: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2886 - accuracy: 0.9130\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1346 - accuracy: 0.9592\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0974 - accuracy: 0.9709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f51ec061820>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_norm, y_train_encoded, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1038 - accuracy: 0.9677\n",
      "Test dataset accuracy : 96.77000045776367\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test_norm, y_test_encoded)\n",
    "print('Test dataset accuracy :', accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8: Predictions\n",
    "\n",
    "### Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('COURSERA_PROJECT_VENV': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6e7475e0f9540d655adbbb089610da45c9ad0f75c62e1456b00631014c84d38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
